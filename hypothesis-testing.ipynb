{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://towardsdatascience.com/hypothesis-testing-with-python-step-by-step-hands-on-tutorial-with-practical-examples-e805975ea96e](https://towardsdatascience.com/hypothesis-testing-with-python-step-by-step-hands-on-tutorial-with-practical-examples-e805975ea96e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Hypotheses\n",
    "First of all, we should understand which scientific question we are looking for an answer to, and it should be formulated in the form of the Null Hypothesis (H₀) and the Alternative Hypothesis (H₁ or Hₐ). Please remember that H₀ and H₁ must be mutually exclusive, and H₁ shouldn’t contain equality:\n",
    "\n",
    "- H₀: μ=x, H₁: μ≠x\n",
    "- H₀: μ≤x, H₁: μ>x\n",
    "- H₀: μ≥x, H₁: μ<x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assumption Check\n",
    "To decide whether to use the parametric or nonparametric version of the test, we should check the specific requirements listed below:\n",
    "\n",
    "- Observations in each sample are independent and identically distributed (IID).\n",
    "- Observations in each sample are normally distributed.\n",
    "- Observations in each sample have the same variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting the Proper Test\n",
    "\n",
    "Then we select the appropriate test to be used. When choosing the proper test, it is essential to analyze how many groups are being compared and whether the data are paired or not. To determine whether the data is matched, it is necessary to consider whether the data was collected from the same individuals. Accordingly, you can decide on the appropriate test using the chart below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![types of test](./images/types-of-test.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "\n",
    "After performing the hypothesis testing, we obtain a related p-value that shows the significance of the test.\n",
    "\n",
    "If the p-value is smaller than the alpha (the significance level), in other words, there is enough evidence to prove H₀ is not valid; you can reject H₀. Otherwise, you fail to reject H₀. Please remember that rejecting H₀ validates H₁. However, failing to reject H₀ does not mean H₀ is valid, nor does it mean H₁ is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![significance-level](./images/significance-level.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. t-test independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/t-test-independent.webp\" height=300 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A university professor gave online lectures instead of face-to-face classes due to Covid-19. Later, he uploaded recorded lectures to the cloud for students who followed the course asynchronously (those who did not attend the lesson but later watched the records). However, he believes that the students who attend class at the class time and participate in the process are more successful. Therefore, he recorded the average grades of the students at the end of the semester. The data is below.\n",
    "\n",
    "`synchronous = [94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]\n",
    "asynchronous = [77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]`\n",
    "\n",
    "Conduct the hypothesis testing to check whether the professor’s belief is statistically significant by using a 0.05 significance level to evaluate the null and alternative hypotheses. Before doing hypothesis testing, check the related assumptions. Comment on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Hypothesis\n",
    "Since the grades are obtained from the different individuals, the data is unpaired.\n",
    "- H₀: μₛ≤μₐ \n",
    "- H₁: μₛ>μₐ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assumption Check\n",
    "\n",
    "- *H₀:* The data is normally distributed.\n",
    "- *H₁:* The data is not normally distributed.\n",
    "\n",
    "Assume that α=0.05. If the p-value is >0.05, it can be said that data is normally distributed.\n",
    "For checking normality, I used Shapiro-Wilk’s W test which is generally preferred for smaller samples however there are other options like Kolmogorov-Smirnov and D’Agostino and Pearson’s test. Please visit https://docs.scipy.org/doc/scipy/reference/stats.html for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp \n",
    "\n",
    "sp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normality(data):\n",
    "    \"\"\"\n",
    "    this function is to test normality of data\n",
    "    \"\"\"\n",
    "    test_stat_normality, p_value_normality = stats.shapiro(data) # performing test on data\n",
    "    print(\"p value:%.4f\" % p_value_normality)\n",
    "\n",
    "    if p_value_normality < 0.05:\n",
    "        # reject null hypothesis\n",
    "        print(\"Reject null hypothesis >> The data is not normally distributed\")\n",
    "    else:\n",
    "        # fail to reject null hypothesys, doesn't mean that alternate is right\n",
    "        print(\"Fail to reject null hypothesis >> The data is normally distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.6556\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "--------------------------------------------------\n",
      "p value:0.0803\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "sync = np.array([94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2,\n",
    "       87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6])\n",
    "asyncr = np.array([77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2])\n",
    "\n",
    "check_normality(sync)\n",
    "print('-'*50)\n",
    "check_normality(asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H₀:* The variances of the samples are the same. \n",
    "\n",
    "*H₁:* The variances of the samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variance_homoginity(group1, group2):\n",
    "    test_stat_var, p_value_var = stats.levene(group1, group2)\n",
    "    print(\"p value:%.4f\" % p_value_var)\n",
    "\n",
    "    if p_value_var < 0.05:\n",
    "        print(\"Reject null hypothesis >> The variances of the samples are different. \")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The variances of the samples are same (not different).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). Suppose the resulting p-value of Levene’s test is less than the significance level (typically 0.05). In that case, the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances.\n",
    "\n",
    "For checking variance homogeneity, I preferred Levene’s test but you can also check Bartlett’s test from here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bartlett.html#scipy.stats.bartlett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.8149\n",
      "Fail to reject null hypothesis >> The variances of the samples are same (not different).\n"
     ]
    }
   ],
   "source": [
    "check_variance_homoginity(sync, asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting the Proper Test\n",
    "Since assumptions are satisfied, we can perform the parametric version of the test for 2 groups and unpaired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.00753598\n",
      " since the hypothesis test is one sided >> use p_value/2 >> p_value_one_sided:0.0038\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest, p_value = stats.ttest_ind(sync, asyncr)\n",
    "\n",
    "print(\"p value:%.8f\" %p_value)\n",
    "print(\" since the hypothesis test is one sided >> use p_value/2 >> p_value_one_sided:%.4f\" %(p_value/2))\n",
    "\n",
    "if p_value/2 < 0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, there is enough evidence to conclude that the average grade of the students who follow the course synchronously is higher than the students who follow the course asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/anova.webp\" height=300 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pediatrician wants to see the effect of formula consumption on the average monthly weight gain (in gr) of babies. For this reason, she collected data from three different groups. The first group is exclusively breastfed children (receives only breast milk), the second group is children who are fed with only formula and the last group is both formula and breastfed children. These data are as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "only_breast=[794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7, 717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1]\n",
    "\n",
    "only_formula=[ 898.8, 881.2, 940.2, 966.2, 957.5, 1061.7, 1046.2, 980.4, 895.6, 919.7, 1074.1, 952.5, 796.3, 859.6, 871.1 , 1047.5, 919.1 , 1160.5, 996.9]\n",
    "\n",
    "both=[976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6, 805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 , 823.6, 818.7, 926.8, 791.7, 948.3]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ccording to this information, conduct the hypothesis testing to check whether there is a difference between the average monthly gain of these three groups by using a 0.05 significance level. If there is a significant difference, perform further analysis to find what caused the difference. Before doing hypothesis testing, check the related assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Hypothesis\n",
    "\n",
    "*H₀:* μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
    "\n",
    "*H₁:* At least one of them is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assumption Check\n",
    "\n",
    "*H₀:* The data is normally distributed.\n",
    "\n",
    "*H₁:* The data is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_breast=[794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7, 717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1]\n",
    "only_formula=[ 898.8, 881.2, 940.2, 966.2, 957.5, 1061.7, 1046.2, 980.4, 895.6, 919.7, 1074.1, 952.5, 796.3, 859.6, 871.1 , 1047.5, 919.1 , 1160.5, 996.9]\n",
    "both=[976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6, 805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 , 823.6, 818.7, 926.8, 791.7, 948.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.4694\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.8879\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.7973\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(only_breast)\n",
    "check_normality(only_formula)\n",
    "check_normality(both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H₀:* The variances of the samples are the same. \n",
    "\n",
    "*H₁:* The variances of the samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.76731188\n",
      "Fail to reject null hypothesis >> The variance of sample are same (not different)\n"
     ]
    }
   ],
   "source": [
    "test_stat_var, p_value_var = stats.levene(only_breast, only_formula, both)\n",
    "print(\"p value:%.8f\" % p_value_var)\n",
    "\n",
    "if p_value_var < 0.05:\n",
    "    print(\"Reject null hypothesis >> The variance of samples are different\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variance of sample are same (not different)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting the Proper Test\n",
    "\n",
    "Since assumptions are satisfied, we can perform the parametric version of the test for more than 2 groups and unpaired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0000\n",
      "Reject null hypothesis >> at least one of them is different\n"
     ]
    }
   ],
   "source": [
    "# Q. why we are performing oneway anova?\n",
    "\n",
    "F, p_value = stats.f_oneway(only_breast, only_formula, both)\n",
    "print(\"p value:%.4f\" % p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject null hypothesis >> at least one of them is different\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> all are same (no difference)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "At this significance level, it can be concluded that at least one of the groups has a different average monthly weight gain. To find which group or groups cause the difference, we need to perform a posthoc test/pairwise comparison as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To avoid family-wise p-value inflation, I used Bonferroni adjustment. You can see your other alternative from here: https://scikit-posthocs.readthedocs.io/en/latest/generated/scikit_posthocs.posthoc_ttest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8y/3b6b9p6d5vjg7ql8yvqrf69w0000gn/T/ipykernel_1419/319522135.py:10: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color:white\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e23da_row0_col0, #T_e23da_row0_col2, #T_e23da_row1_col1, #T_e23da_row2_col0, #T_e23da_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_e23da_row0_col1, #T_e23da_row1_col0, #T_e23da_row1_col2, #T_e23da_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e23da\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e23da_level0_col0\" class=\"col_heading level0 col0\" >only_breast</th>\n",
       "      <th id=\"T_e23da_level0_col1\" class=\"col_heading level0 col1\" >only_formula</th>\n",
       "      <th id=\"T_e23da_level0_col2\" class=\"col_heading level0 col2\" >both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e23da_level0_row0\" class=\"row_heading level0 row0\" >only_breast</th>\n",
       "      <td id=\"T_e23da_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_e23da_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_e23da_row0_col2\" class=\"data row0 col2\" >0.129454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e23da_level0_row1\" class=\"row_heading level0 row1\" >only_formula</th>\n",
       "      <td id=\"T_e23da_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_e23da_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_e23da_row1_col2\" class=\"data row1 col2\" >0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e23da_level0_row2\" class=\"row_heading level0 row2\" >both</th>\n",
       "      <td id=\"T_e23da_row2_col0\" class=\"data row2 col0\" >0.129454</td>\n",
       "      <td id=\"T_e23da_row2_col1\" class=\"data row2 col1\" >0.000004</td>\n",
       "      <td id=\"T_e23da_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x144c6c410>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "posthoc_df = sp.posthoc_ttest([only_breast, only_formula, both], equal_var=True, p_adjust=\"bonferroni\")\n",
    "\n",
    "group_names = [\"only_breast\", \"only_formula\", \"both\"]\n",
    "\n",
    "posthoc_df.columns = group_names\n",
    "posthoc_df.index = group_names\n",
    "\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color:white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this significance level, it can be concluded that:\n",
    "\n",
    "*“only breast”* is different than *“only formula”*\n",
    "\n",
    "*“only formula”* is different than both *“only breast”* and *“both”*\n",
    "\n",
    "*“both”* is different than *“only formula”*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Mann Whitney U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/mann-whitney-u.webp\" height=300 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A human resource specialist working in a technology company is interested in the overwork time of different teams. To investigate whether there is a difference between overtime of the software development team and the test team, she selected 17 employees randomly in each of the two teams and recorded their weekly average overwork time in terms of an hour. The data is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team=[6.2, 7.1, 1.5, 2,3 , 2, 1.5, 6.1, 2.4, 2.3, 12.4, 1.8, 5.3, 3.1, 9.4, 2.3, 4.1]\n",
    "developer_team=[2.3, 2.1, 1.4, 2.0, 8.7, 2.2, 3.1, 4.2, 3.6, 2.5, 3.1, 6.2, 12.1, 3.9, 2.2, 1.2 ,3.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this information, conduct the hypothesis testing to check whether there is a difference between the overwork time of two teams by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Hypothesis\n",
    "\n",
    "*H₀:* μ₁≤μ₂ \n",
    "\n",
    "*H₁:* μ₁>μ₂\n",
    "\n",
    "### 2. Assumption Check\n",
    "\n",
    "*H₀:* The data is normally distributed.\n",
    "\n",
    "*H₁:* The data is not normally distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0046\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.0005\n",
      "Reject null hypothesis >> The data is not normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_team)\n",
    "check_normality(developer_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H₀:* The variances of the samples are the same. \n",
    "\n",
    "*H₁:* The variances of the samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.5410\n",
      "Fail to reject null hypothesis >> The variances of the samples are same (not different).\n"
     ]
    }
   ],
   "source": [
    "check_variance_homoginity(test_team, developer_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.8226\n",
      "Fail to reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest, p_value = stats.mannwhitneyu(test_team, developer_team, alternative=\"two-sided\")\n",
    "print(\"p value:%.4f\" % p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Rejected null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, it can be said that there is no statistically significant difference between the average overwork time of the two teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Kruskal-Wallis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/kruskals-walli.webp\" height=300 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An e-commerce company regularly advertises on YouTube, Instagram, and Facebook for its campaigns. However, the new manager was curious about if there was any difference between the number of customers attracted by these platforms. Therefore, she started to use Adjust, an application that allows you to find out where your users come from. The daily numbers reported from Adjust for each platform are as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Youtube=[1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956, 2146, 2151, 1943, 2125]\n",
    "Instagram = [2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340., 2349., 2241., 2396., 2244., 2267., 2281.]\n",
    "Facebook = [2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178., 2113., 2048., 2443., 2265., 2095., 2528.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this information, conduct the hypothesis testing to check whether there is a difference between the average customer acquisition of these three platforms using a 0.05 significance level. If there is a significant difference, perform further analysis to find that caused the difference. Before doing hypothesis testing, check the related assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Hypothesis\n",
    "\n",
    "*H₀: μ₁=μ₂=μ₃* or The mean of the samples is the same.\n",
    "\n",
    "*H₁:* At least one of them is different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assumption Check\n",
    "\n",
    "*H₀:* The data is normally distributed.\n",
    "\n",
    "*H₁:* The data is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0285\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.4156\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1716\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(Youtube)\n",
    "check_normality(Instagram)\n",
    "check_normality(Facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H₀:* The variances of the samples are the same. \n",
    "\n",
    "*H₁:* The variances of the samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0012\n",
      "Rejected null hypothesis >> The vaiances of the samples are different\n"
     ]
    }
   ],
   "source": [
    "stat, p_levene_var = stats.levene(Youtube, Instagram, Facebook)\n",
    "print(\"p value:%.4f\" %p_levene_var)\n",
    "\n",
    "if p_levene_var < 0.05:\n",
    "    print(\"Rejected null hypothesis >> The vaiances of the samples are different\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same (no difference)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting the Proper Test\n",
    "\n",
    "The normality and variance homogeneity assumptions are not satisfied, therefore we need to use the nonparametric version of ANOVA for unpaired data (the data is collected from different sources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0000\n",
      "Rejected null hypothesis >> at least one of them is different\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.kruskal(Youtube, Instagram, Facebook)\n",
    "print(\"p value:%.4f\" %p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Rejected null hypothesis >> at least one of them is different\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> all are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "\n",
    "*At this significance level, at least one of the average customer acquisition number is different.*\n",
    "\n",
    "*Note:* Since the data is not normal, the nonparametric version of posthoc test is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8y/3b6b9p6d5vjg7ql8yvqrf69w0000gn/T/ipykernel_1419/2424315162.py:8: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  posthoc_df.style.applymap(lambda x: \"background-color: violet\" if x<0.05 else \"background-color: white\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2927c_row0_col0, #T_2927c_row1_col1, #T_2927c_row1_col2, #T_2927c_row2_col1, #T_2927c_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_2927c_row0_col1, #T_2927c_row0_col2, #T_2927c_row1_col0, #T_2927c_row2_col0 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2927c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2927c_level0_col0\" class=\"col_heading level0 col0\" >Youtube</th>\n",
       "      <th id=\"T_2927c_level0_col1\" class=\"col_heading level0 col1\" >Instagram</th>\n",
       "      <th id=\"T_2927c_level0_col2\" class=\"col_heading level0 col2\" >Facebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2927c_level0_row0\" class=\"row_heading level0 row0\" >Youtube</th>\n",
       "      <td id=\"T_2927c_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_2927c_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_2927c_row0_col2\" class=\"data row0 col2\" >0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2927c_level0_row1\" class=\"row_heading level0 row1\" >Instagram</th>\n",
       "      <td id=\"T_2927c_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_2927c_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_2927c_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2927c_level0_row2\" class=\"row_heading level0 row2\" >Facebook</th>\n",
       "      <td id=\"T_2927c_row2_col0\" class=\"data row2 col0\" >0.000135</td>\n",
       "      <td id=\"T_2927c_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "      <td id=\"T_2927c_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x144c2cdd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posthoc_df = sp.posthoc_ttest([Youtube, Instagram, Facebook], p_adjust=\"bonferroni\")\n",
    "\n",
    "group_names = [\"Youtube\", \"Instagram\", \"Facebook\"]\n",
    "\n",
    "posthoc_df.columns = group_names\n",
    "posthoc_df.index = group_names\n",
    "\n",
    "posthoc_df.style.applymap(lambda x: \"background-color: violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of customers coming from YouTube is different than the other (actually smaller than the others)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. t-test dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/t-test-dependent.webp\" height=300 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The University Health Center diagnosed eighteen students with high cholesterol in the previous semester. Healthcare personnel told these patients about the dangers of high cholesterol and prescribed a diet program. One month later, the patients came for control, and their cholesterol level was reexamined. Test whether there is a difference in the cholesterol levels of the patients.\n",
    "According to this information, conduct the hypothesis testing to check whether there is a decrease in the cholesterol levels of the patients after the diet by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_before_diet=[224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227]\n",
    "test_results_after_diet=[198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Hypothesis\n",
    "\n",
    "*H₀:* μ<sub>d</sub>>=0 or The true mean difference is equal to or bigger than zero.\n",
    "\n",
    "*H₁:* μ<sub>d</sub><0 or The true mean difference is smaller than zero.\n",
    "\n",
    "### 2. Assumption Check\n",
    "\n",
    "- The dependent variable must be continuous (interval/ratio) \n",
    "- The observations are independent of one another.\n",
    "- The dependent variable should be approximately normally distributed.\n",
    "\n",
    "*H₀:* The data is normally distributed.\n",
    "\n",
    "*H₁:* The data is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1635\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1003\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_results_before_diet)\n",
    "check_normality(test_results_after_diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting the Proper Test\n",
    "The data is paired since data is collected from the same individuals and assumptions are satisfied, then we can use the dependent t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value: 0.0000 one tailed p value: 0.000004\n",
      "Rejected null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test_stat, p_value_paired = stats.ttest_rel(test_results_before_diet, test_results_after_diet)\n",
    "\n",
    "print(\"p value: %.4f\" % p_value_paired, \"one tailed p value: %.6f\" % (p_value_paired/2))\n",
    "\n",
    "if p_value_paired < 0.05:\n",
    "    print(\"Rejected null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "\n",
    "*At this significance level, there is enough evidence to conclude mean cholesterol level of patients has decreased after the diet.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Wilcoxon signed-rank test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video src=\"./images/wilcoxon.html\" controls height=300 width=500></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A venture capitalist wanted to invest in a startup that provides data compression without any loss in quality, but there are two competitors: PiedPiper and EndFrame. Initially, she believed the performance of the EndFrame could be better but still wanted to test it before the investment. Then, she gave the same files to each company to compress and recorded their performance scores. The data is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "piedpiper=[4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25]\n",
    "endframe = [4.27, 3.93, 4.01, 4.07, 3.87, 4. , 4. , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this information, conduct the related hypothesis testing by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results.\n",
    "\n",
    "### 1. Defining Hypothesis\n",
    "\n",
    "Since the performance scores are obtained from the same files, the data is paired.\n",
    "\n",
    "H₀: μ<sub>d</sub>>=0 or The true mean difference is equal to or bigger than zero.\n",
    "\n",
    "H₁: μ<sub>d</sub><0 or The true mean difference is smaller than zero.\n",
    "\n",
    "### 2. Assumption Check\n",
    "\n",
    "- The dependent variable must be continuous (interval/ratio) \n",
    "- The observations are independent of one another.\n",
    "- The dependent variable should be approximately normally distributed.\n",
    "\n",
    "H₀: The data is normally distributed.\n",
    "\n",
    "H₁: The data is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0304\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.9587\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(piedpiper)\n",
    "check_normality(endframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting the Proper Test\n",
    "\n",
    "The normality assumption is not satisfied; therefore, we need to use the nonparametric version of the paired test, namely the Wilcoxon Signed Rank test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value: 0.000214 >> one tailed p value: 0.000107\n",
      "one sided p value:0.000107\n",
      "Rejected null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test, p_value = stats.wilcoxon(piedpiper, endframe) # alternative defaut two sided\n",
    "\n",
    "print(\"p value: %.6f\" % p_value, \">> one tailed p value: %.6f\" % (p_value/2))\n",
    "\n",
    "test, one_sided_pvalue = stats.wilcoxon(endframe, piedpiper, alternative=\"less\")\n",
    "print(\"one sided p value:%.6f\" %(one_sided_pvalue))\n",
    "if p_value < 0.05:\n",
    "    print(\"Rejected null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "\n",
    "*At this significance level, there is enough evidence to conclude that the performance of the PiedPaper is better than the EndFrame.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. Friedman Chi-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/frideman-chi-squre.webp\" height=300 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A researcher was curious about whether there is a difference between the methodology she developed, C, and baseline methods A and B in terms of performance. Therefore, she decided to design different experiments and recorded the achieved accuracy by each method. The below table shows the achieved accuracy on test sets by each method. Please note that the same train and test sets were used for each method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment | A | B | C\n",
    "-- | -- | -- | -- \n",
    "E1| 89.8 | 90.0 | 91.5\n",
    "E2| 89.9| 90.1| 90.7\n",
    "E3| 88.6| 88.8| 90.3\n",
    "E4| 88.7| 88.9| 90.4\n",
    "E5| 89.6| 89.9| 90.2\n",
    "E6| 89.7| 90.0| 90.3\n",
    "E7| 89.2|89.0 | 90.2\n",
    "E8| 89.3| 89.2| 90.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_a = [89.8, 89.9, 88.6, 88.7, 89.6, 89.7, 89.2, 89.3]\n",
    "method_b = [90.0, 90.1, 88.8, 88.9, 89.9, 90.0, 89.0, 89.2]\n",
    "method_c = [91.5, 90.7, 90.3, 90.4, 90.2, 90.3, 90.2, 90.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this information, conduct the hypothesis testing to check whether there is a difference between the performance of the methods by using a 0.05 significance level. If there is a significant difference, perform further analysis to find which one caused the difference. Before doing hypothesis testing, check the related assumptions. Comment on the results.\n",
    "\n",
    "### 1. Defining Hypothesis\n",
    "\n",
    "*H₀:* μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
    "\n",
    "*H₁:* At least one of them is different.\n",
    "\n",
    "### 2. Assumption Check\n",
    "\n",
    "*H₀:* The data is normally distributed.\n",
    "\n",
    "*H₁:* The data is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.3076\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0515\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0016\n",
      "Reject null hypothesis >> The data is not normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(method_a)\n",
    "check_normality(method_b)\n",
    "check_normality(method_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value: 0.195340\n",
      "Fail to reject null hypothesis >> The variance of the samples are same (no difference).\n"
     ]
    }
   ],
   "source": [
    "stat, p_value_var = stats.levene(method_a, method_b, method_c)\n",
    "\n",
    "print(\"p value: %.6f\" % p_value_var)\n",
    "\n",
    "if p_value_var < 0.05:\n",
    "    print(\"Reject null hypothesis >> The varience of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variance of the samples are same (no difference).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting the Proper Test\n",
    "\n",
    "There are three groups, but the normality assumption is violated. So, we need to use the nonparametric version of ANOVA for paired data since the accuracy scores are obtained from the same test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value: 0.0015\n",
      "Rejected null hypothesis\n",
      "89.35 89.49 90.49\n"
     ]
    }
   ],
   "source": [
    "test_stat, p_value = stats.friedmanchisquare(method_a, method_b, method_c)\n",
    "\n",
    "print(\"p value: %.4f\" % p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Rejected null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")\n",
    "\n",
    "print(np.round(np.mean(method_a), 2), np.round(np.mean(method_b), 2), np.round(np.mean(method_c), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Decision and Conclusion\n",
    "\n",
    "*At this significance level, at least one of the methods has a different performance.*\n",
    "\n",
    "*Note:* Since the data is not normal, the nonparametric version of the posthoc test is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8y/3b6b9p6d5vjg7ql8yvqrf69w0000gn/T/ipykernel_1419/3736311988.py:11: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  posthoc_df.style.applymap(lambda x: \"background-color: violet\" if x<0.05 else \"background-color: white\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c229f_row0_col0, #T_c229f_row0_col1, #T_c229f_row1_col0, #T_c229f_row1_col1, #T_c229f_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_c229f_row0_col2, #T_c229f_row1_col2, #T_c229f_row2_col0, #T_c229f_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c229f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c229f_level0_col0\" class=\"col_heading level0 col0\" >method A</th>\n",
       "      <th id=\"T_c229f_level0_col1\" class=\"col_heading level0 col1\" >method B</th>\n",
       "      <th id=\"T_c229f_level0_col2\" class=\"col_heading level0 col2\" >method C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c229f_level0_row0\" class=\"row_heading level0 row0\" >method A</th>\n",
       "      <td id=\"T_c229f_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_c229f_row0_col1\" class=\"data row0 col1\" >0.078125</td>\n",
       "      <td id=\"T_c229f_row0_col2\" class=\"data row0 col2\" >0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c229f_level0_row1\" class=\"row_heading level0 row1\" >method B</th>\n",
       "      <td id=\"T_c229f_row1_col0\" class=\"data row1 col0\" >0.078125</td>\n",
       "      <td id=\"T_c229f_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_c229f_row1_col2\" class=\"data row1 col2\" >0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c229f_level0_row2\" class=\"row_heading level0 row2\" >method C</th>\n",
       "      <td id=\"T_c229f_row2_col0\" class=\"data row2 col0\" >0.023438</td>\n",
       "      <td id=\"T_c229f_row2_col1\" class=\"data row2 col1\" >0.023438</td>\n",
       "      <td id=\"T_c229f_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1469de550>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([method_a, method_b, method_c])\n",
    "\n",
    "posthoc_df = sp.posthoc_wilcoxon(data, p_adjust=\"holm\")\n",
    "\n",
    "# posthoc_df = sp.posthoc_nemenyi_friedman(data.T) # another option for the posthoc test\n",
    "\n",
    "group_names = ['method A', \"method B\", \"method C\"]\n",
    "posthoc_df.columns = group_names\n",
    "posthoc_df.index = group_names\n",
    "\n",
    "posthoc_df.style.applymap(lambda x: \"background-color: violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method C outperformed others and achieved better accuracy scores than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8. The goodness of Fit (Bonus :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/goodness-of-fit.webp\" height=300 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An analyst of a financial investment company is curious about the relationship between gender and risk appetite. A random sample was taken of 660 customers from the database. The customers in the sample were classified according to their gender and their risk appetite. The result is given in the following table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender/Risk Appetite| Very Low| Low | Medium | High| Very High| Total\n",
    "-- | -- | -- | -- | -- | -- | --\n",
    "Female| 53 | 23 | 30 | 36 | 88 | 230\n",
    "Male | 71 | 48 | 51 | 57 | 203 | 430\n",
    "Total| 124 | 71 | 81 | 93 | 291 | 660"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the hypothesis that the risk appetite of the customers in this company is independent of their gender. Use *α = 0.01*\n",
    "\n",
    "### 1. Defining Hypothesis\n",
    "\n",
    "*H₀:* Gender and risk appetite are independent. \n",
    "*H₁:* Gender and risk appetite are dependent.\n",
    "\n",
    "### 2. Selecting the Proper Test and Assumption Check\n",
    "\n",
    "chi2 test should be used for this question. This test is known as the goodness-of-fit test. It implies that if the observed data are very close to the expected data. The assumption of this test every *E<sub>i</sub> ≥ 5* (in at least 80% of the cells) is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected frequencies:\n",
      "  [[ 42.97  24.6   28.07  32.22 100.14]\n",
      " [ 81.03  46.4   52.93  60.78 188.86]]\n",
      "degree of freedom : 4\n",
      "test stats: 7.6806\n",
      "p value: 0.1040\n"
     ]
    }
   ],
   "source": [
    "obs = np.array([[53, 23, 30, 36, 86], [71, 48, 51, 57, 203]])\n",
    "chi2, p, dof, ex = stats.chi2_contingency(obs, correction=False)\n",
    "\n",
    "print(\"expected frequencies:\\n \", np.round(ex, 2))\n",
    "print(\"degree of freedom :\",dof)\n",
    "print(\"test stats: %.4f\" % chi2)\n",
    "print(\"p value: %.4f\" % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical stat: 13.2767\n"
     ]
    }
   ],
   "source": [
    "# calculate critical stat\n",
    "\n",
    "alpha = 0.01\n",
    "df = (5 - 1)*(2 - 1)\n",
    "critical_test = stats.chi2.ppf((1-alpha), df)\n",
    "print(\"critical stat: %.4f\" % critical_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is larger than α=0.01 ( or calculated statistic=7.14 is smaller than the critical statistic=13.28) → Fail to Reject H₀. At this significance level, it can be concluded that gender and risk appetite are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
